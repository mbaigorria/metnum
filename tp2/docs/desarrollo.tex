\section{PageRank}

\subsection{Modelado para paginas web}

El algoritmo PageRank fue ideado en un principio para buscar de darle alguna medida de relevancia a los sitios web en internet. El mismo tiene dos interpretaciones equivalentes, que serán expuestas a continuación.

El problema se modela a partir de un grafo $G(Web,Links)$ donde $Web$ es el conjunto de sitios web y $Links$ es la cantidad de conexiones entre sitios. Consideremos que toda pagina web $u \in Web$ esta representada por un vértice y la relación entre paginas por un link con una arista. Una representación posible del grafo es mediante matrices de adyacencia. Definimos la matriz de adyacencia o conectividad $W \in \{0,1\}^{n \times n}$ de forma tal que $w_{ij} = 1$ si la pagina $j$ tiene un link a la pagina $i$ y $w_{ij} = 0$ en caso contrario. Por lo tanto, la cantidad de paginas a las que la pagina $u$ apunta ($d_{out}(u)$) se puede calcular como $n_j = \sum_{i=1}^{n} w_{ij}$.

\subsubsection{Propiedades}

Sea $x_j$ el puntaje asignado a la pagina o vértice $j \in Web$ y otra pagina $u \in Web$. La idea es buscar una medida que cumpla con las siguientes propiedades:
\begin{itemize}
  \item La relevancia de todo sitio web es positiva.
  \item La relevancia de un sitio web debe aumentar a medida que mas sitios unicos lo apuntan.
  \item La relevancia derivada de otro sitio web debe depender de su propia relevancia. Es decir, es mas valioso que me linkee un sitio relevante que uno no relevante. En caso de no cumplirse esta propiedad, el ranking seria fácilmente manipulable al permitir que un usuario cree muchos sitios que linkeen a uno para darle relevancia.
  \item La relevancia de todos los sitios web debe sumar uno. De esta manera estamos ante una distribución de probabilidad de los sitios. Mas adelante veremos que al interpretar esto mediante Cadenas de Markov existe una interpretación directa: la relevancia se puede ver como la proporción del tiempo total que un usuario pasa en ese sitio.
\end{itemize} 

Por lo tanto, estamos buscando una medida de relevancia tal que la importancia obtenida por la pagina $u$ obtenida por el link de la pagina $v$ sea proporcional a la relevancia de $v$ e inversamente proporcional al grado de $v$. El aporte del link de $v$ a $u$ entonces es $x_u = x_v / n_v$. Luego, sea $L_k \subseteq Web$ el conjunto de paginas que tienen un link a la pagina $k$. Por lo tanto, la relevancia total de un sitio sera:

\begin{eqnarray}
x_k = \sum_{j \in L_k} \frac{x_j}{n_j},~~~~k = 1,\dots,n. \label{eq:basicmodel}
\end{eqnarray}

Notar que esta es de cierta manera una definición recursiva. La relevancia de un sitio $u$ puede depender de la relevancia de un sitio $v$, y luego la de $v$ puede depender de la de $u$. A priori calcular la relevancia de un sitio puede parecer sumamente complicado, pero luego veremos que al plantearlo como un sistema de ecuaciones esta dificultad per se ya no se presenta.

Definimos entonces una matriz de transición o adyacencia con pesos en las aristas $P \in \mathbb{R}^{n \times n}$ tal que $p_{ij} = 1 / n_j$ si $w_{ij} = 1$ y $p_{ij} = 0$ en caso contrario. Luego, el modelo planteado en (\ref{eq:basicmodel}) para toda pagina web se puede expresar $Px = x$ donde $x \in \mathbb{R}^n$. Notar que esto es equivalente a encontrar el autovector de autovalor 1 tal que $x_i > 0$ y $\sum_{n=1}^{n} x_i = 1$. Notar que si logramos probar que bajo ciertas condiciones nuestra matriz de transición tiene autovalor 1, el signo de todos los elementos de un autovector es el mismo y la dimension del autoespacio es 1 ya tenemos un ranking valido. Esto se debe a que cualquier autovector puede ser reescalado a uno de norma unitaria con $x_i \geq 0$.

\pagebreak

\subsubsection{Existencia y Unicidad}

Bryan y Leise \cite{Bryan2006} analiza y prueba las condiciones bajo las que podemos garantizar que:
\begin{itemize}
\item La matriz de transición tiene autovalor 1.
\item La dimension del autoespacio asociado al autovalor 1 es 1. Es deseable que el ranking asociado a una matriz de transición sea único.
\item El signo de todos los elementos del autovector asociado al autovalor 1 es el mismo.
\end{itemize}

Veamos bajo que condiciones nuestra matriz de transición cumple con estas propiedades:

\begin{definition}
Una matriz cuadrada se llama estocástica por columnas si todos sus elementos son positivos y la suma de cada columna es igual a 1.
\end{definition}

A partir de esta definición se puede probar la siguiente proposición:
\begin{proposition}
Toda matriz estocástica por columnas tiene a 1 como autovalor.
\end{proposition}

Esto significa que si no existen \texttt{dangling nodes}, es decir, vértices con $d_{out} = 0$, podemos garantizar que nuestra matriz de transición es estocástica por columnas.

Notar que bajo las condiciones actuales no podemos garantizar que si existe el autoespacio asociado al autovalor 1, el mismo tenga dimension 1. Intuitivamente, esto se debe a que el grafo de la web puede tener varias componentes conexas. Como comparamos sitios web que no están relacionados? Justamente la relación, ya sea directa o indirecta mediante transitividad me da algún tipo de relación de orden. Al no tener una relación de orden entre dos sitios web bien definida, es razonable que existan múltiples autovectores, es decir, rankings. Esto se puede ver claramente en la pagina 4 del paper de Bryan y Leise \cite{Bryan2006}.

Por lo tanto, la idea es básicamente buscar algún tipo de transformación relevante de mi matriz de transición que me permita garantizar que no voy a tener \texttt{dangling nodes} y ademas que solo tenga una componente conexa, es decir, que el grafo sea conexo. Definimos la siguiente matriz de transición, donde $v \in \mathbb{R}^{n \times n}$, con $v_i = 1 / n$ y $d \in \{0,1\}^n$,  $d_i = 1$ si $n_i = 0$ y $d_i = 0$ como:

\begin{eqnarray*}
D & = & v d^t \\
P_1 & = & P + D.
\end{eqnarray*}

De esta manera, en caso de tener una pagina web que es un \texttt{dangling node}, le asignamos un link uniforme a todos los sitios web $u \in Web$. Una interpretación equivalente es tomar a la matriz de transiciones como la matriz que describe una Cadena de Markov, donde el link pesado representa la probabilidad de dirigirse de una pagina a la otra. Por lo tanto, esta transformación se puede interpretar como que que existe una probabilidad uniforme de ir de uno de estos sitios a cualquiera de la web. Esto normalmente se conoce como el \texttt{navegante aleatorio}.

Tambien podemos considerar la posibilidad de que el navegante aleatorio se dirija a una pagina web que no esta linkeada a la pagina a la que esta actualmente. Este fenómeno se conoce como teletransportación. Para incluirlo al modelo, tomemos un numero $c \in [0,1]$ y transformemos la matriz de transiciones de la siguiente manera, donde $\bar{1} \in \mathbb{R}^n$ es un vector tal que todos sus componentes valen 1:

\begin{eqnarray*}
E & = & v \bar{1}^t \\
P_2 & = & cP_1 + (1-c)E,
\end{eqnarray*}

Notar que en caso de tener $c=1$, estamos en la matriz de transición sin teletransportación. Por otro lado, si $c=1$ estamos en el caso donde solo hay teletransportación y no importa la estructura del grafo de la web.

Esta nueva matriz de transición, dado que es estocástica por columnas y no tiene \texttt{dangling nodes}, nos garantiza que la dimension del autoespacio generado por el autovector de autovalor 1 es unitaria. Solo nos falta mostrar que todo autovector tiene todos sus elementos del mismo signo. Es facil probar la siguiente proposicion:

\begin{proposition}
Si la matriz M es positiva y estocástica por columnas, entonces todo autovector en $V_1(M)$ tiene todos sus elementos positivos o negativos.
\end{proposition}

Por lo tanto, ya probamos la existencia del autovector de norma 1 asociado al autovalor 1 de la matriz de transición transformada. El siguiente lema nos garantiza su unicidad. Su respectiva demostración se encuentra nuevamente en la pagina 7 del paper de Bryan y Leise \cite{Bryan2006}.

\begin{lemma}
\item Si M es positiva y estocástica por columnas, entonces $V_1(M)$ tiene dimension 1.
\end{lemma}

\subsection{Modelado para Tenis}

Hacer referencia al paper de Govan et al. Explicar existencia y unicidad haciendo referencia a las pruebas de modelado de paginas web.

\subsection{Eliminacion Gausiana}

Esta seccion solo la pongo para que la consideres. Se podra hacer eliminacion gausiana con pivoteo para (P-I)x = 0? Igual si es posible es de orden cubico, con la web de millones de paginas se te va al carajo. Es solo para enriquecer la discusion.

\subsection{Representacion del grafo}

Ya hemos demostrado las condiciones necesarias para poder obtener el autovector asociado al autovalor dominante de una matriz de Markov. 
Ahora debemos proceder a calcular el mismo. Para esto, tenemos que tener en cuenta las cualidades del sistema y el método de resolución del algoritmo. Recordemos que en general, el grafo que representa la web tenderá a ser desconexo y muy grande, es decir, que podrán existir dos o mas rankings diferentes. Por lo tanto la matriz 
de transiciones puede ser muy esparsa e inclusive puede suceder que una página no tenga links de salida, dando lugar a dangling nodes. Para solucionar estos inconvenientes, con lo visto anteriormente disponemos de dos soluciones. Para los dangling nodes, la solución consiste en sumar una columna con probabilidad 1/n a la columna de ceros, esto en si, se puede interpretar como la probalidad de navegación aleatoria que previamente describimos. Aunque con esto no solucionamos el problema de la esparsidad de la matriz en si y el de poder tener mas de un ranking diferente. Para esto último, se agregó la matriz de probabilidad de teletransportación.

Dada esta definición, la matriz de transiciones resultante no es esparsa. 
Para sistemas muy grandes, esto puede resultar contraproducente a la hora de obtener el autovector asociado, dado que la complejidad espacial y temporal aumenta  considerablemente con la cantidad de información representada en la matriz. Sin embargo existe un resultado que podremos utilizar para mejorar la eficiencia del algoritmo en términos de complejidad temporal y espacial. El mismo se basa en la idea de Kamvar et al. \cite[Algoritmo 1]{Kamvar2003} para el calculo del autovector. Este resultado nos permite utilizar la matriz original de transiciones sin modificar en lo absoluto, pero si cambiando su representación, valiendonos de una buena estructura para almacenar las entradas de la misma. 

Las cualidades de la matriz hacen que sea razonable intentar pensar en una forma de representar solo las entradas que no sean ceros, y dado que la matriz suele ser esparsa, la misma contendrá muchos ceros que podrían no ser representados. Para esto optamos por una de entre las 3 siguientes estructuras de representación:

\begin{itemize}
\item Dictionary of Keys ($DOK$)

\item Compressed Sparse Row ($CSR$)

\item Compressed Sparse Column ($CSC$)
\end{itemize}

De todas estas representaciones posibles, para este t.p optamos por $CSR$. Aún así no haremos una elección sin una justificación apropiada del porque consideramos que es la mejor para nuestro trabajo, dado que como en toda estructura de datos, siempre existen pros y contras. Nos encargaremos en lo que sigue de exponer estos detalles para dejar en claro nuestro punto de vista. 

\begin{itemize}
\item Dictionary of Keys ($DOK$)
\end{itemize}
Consiste en un diccionario que mapea pares de fila-columa a la entrada. No se representan las entradas nulas. El formato es bueno para gradualmente construir una matriz esparsa en orden aleatorio, pero pobre para iterar sobre valores distintos de cero en orden lexicográfico. Uno construye típicamente una matriz en este formato y luego se convierte en otro formato más eficiente para su procesamiento.

\begin{itemize}
\item Compressed Sparse Row ($CSR$)
\end{itemize}
Pone las entradas no nulas de las filas de la matriz en posiciones de memoria contiguas. Suponiendo que tenemos una matriz dispersa no simétrica, creamos vectores: uno para los números de punto flotante ($val$), y los otros dos para enteros ($col\_ind$, $row\_ptr$). El vector $val$ almacena los valores de los elementos distintos de cero de la matriz, de izquierda a derecha y de arriba hacia abajo. El vector $col\_ind$ almacena los índices de columna de los elementos en el vector $val$. Es decir, si $val(k) = a_ij$ entonces $col\_ind(k) = j$. El vector $row\_ptr$ almacena los lugares en el vector $val$ que comienza y termina una fila, es decir, si $val(k) = a_ij$ entonces $row_ptr(i) \leq k \leq row\_ptr(i+1)$. Por convención, se define $row\_ptr(n+1) = nnz$, en donde $nnz$ es el número de entradas no nulas en la matriz. Los ahorros de almacenamiento de este enfoque es significativo. En lugar de almacenar elementos $n^2$, solamente necesitamos $2nnz + n$ lugares de almacenamiento.

Veamos con un ejemplo como seria la representacion:
\\\\
$\hspace{3.2cm}\begin{pmatrix} 0 & 0 & 0 & 0 \\ 5 & 8 & 0 & 0 \\ 0 & 0 & 3 & 0 \\ 0 & 6 & 0 & 0 \\ \end{pmatrix}$
\\\\
Es una matrix de 4x4 con 4 entradas no nulas. Luego:

   $val$  = [ 5 8 3 6 ]
   $row\_ptr$ = [ 0 0 2 3 4 ]
   $col\_ind$ = [ 0 1 2 1 ]

\begin{itemize}
\item Compressed Sparse Column ($CSC$)
La idea es analoga a $CSR$, pero la compresion se hace por columnas es decir, si $CSR$ comprime $A$, $CSC$ comprime $A^t$  
\end{itemize}

Sobre la matriz definida para $CSR$, con $CSC$ obtenemos lo siguiente

   $val$  = [ 5 8 6 3 ]
   $col\_ptr$ = [ 0 1 3 4 4 ]   
   $row\_ind$ = [ 1 1 2 3 ]

Todos los resultados anteriores permiten evitar representar valores nulos.	
El motivo de nuestra elección se debe a que $CSR$ ofrece una buena representación de las filas de la matriz y es más eficiente a la hora de hacer operaciones del tipo A*x (matriz-vector) que es lo que nos interesa en el método de la potencia que realiza pageRank. $CSC$ en cambio, es efectiva para el producto x*A (vector-matriz) dado que la misma ofrece una mejor representación de las columnas. En contra partida, tanto $CSR$ como $CSC$, no permiten construcción incremental aleatoria, que si ofrece $DOK$, es decir, que cambios a la esparsidad de la matriz son costosos. En general están pensadas para ser estáticas, pero esto no es un inconveniente en nuestro caso, dado que no se realizaran cambios en la esparsidad de la matriz durante el proceso.

En el presente trabajo utilizaremos la idea de Kamvar et al. \cite[Algoritmo 1]{Kamvar2003} para el calculo del autovector valiendonos de nuestra estructura de representación elegida y compararemos los resultados con el algoritmo standard para mostrar que al final de cuentas, si el sistema es muy grande y esparso, puede resultar muy beneficioso en terminos de complejidad espacial y temporal.

\subsection{Computo: Método de la Potencia}

\textbf{LO SIGUIENTE ES PARA MAURO. HACELO EN TE RO (SI ENTERO), NO SEAS PAJERO. QUIERO LA SECCION BIEN COMPLETA CON LOS PUNTOS OPCIONALES, SOLO TENES QUE HACER ESTO. IMAGINATE QUE YO ME MORFE ESCRIBIR TODO.}

La pregunta mas importante del trabajo, dado la matriz de transiciones $P$ que garantiza la existencia y unicidad del autovector de norma 1 asociado al autovalor 1, como lo computamos?

\subsubsection{Correctitud}

La idea básicamente es generar la secuencia $x_k = Px_{k-1}$ y tomar $k\to\infty$. Se puede probar que para este caso no importa el valor inicial que asignemos a la secuencia $x_0$, el vector converge al autovector asociado al mayor autovalor de P. Se puede probar que todo autovalor $\lambda$ de $P$ satisface que $|\lambda| < 1$.

Otra propiedad interesante es que el método de la potencia va a converger de forma asintotica siguiendo $\norm{Px_k - q}_1 \approx |\lambda_2| \norm{x-q}_1$ donde $\lambda_2$ es el segundo autovalor mas grande de P. \textbf{Mauro revisa esto y fijate si sirve y se puede hacer algún criterio de parada copado.}

\subsubsection{Valor Inicial}

Elijo uno uniforme (todos con la misma relevancia y norma 1), o uno bien contra las esquinas (obvio que no)? Con esto hay que experimentar un cachito igual.

\subsubsection{Criterio de Parada}

Diferencias entre normas 1 o hay algo mejor?

\subsubsection{Complejidad}

Cual es la complejidad? Discutir que para deportes mucho no importa, pero para paginas web si.

\subsubsection{Otras propiedades}

Mirar esto antes de resolver lo siguiente...

Sin embargo, en Kamvar et al. se propone una forma alternativa de computar la secuencia. Este resultado debe ser utilizado para mejorar el almacenamiento de los datos. Esta relacionado con el punto de representacion del grafo esto? Ni idea.

... seguir

\textbf{LO SIGUIENTE ES PARA MAURO. HACELO, NO SEAS PAJERO. SI, TE LO DIGO DENUEVO PORQUE SE QUE LO VAS A TRATAR DE EVITAR. NO TE PEDI MUCHO. ESTO ES PARA EL FINAL IGUAL, CUANDO YA TERMINASTE TODO LO DE ARRIBA.}

\begin{itemize}
\item Demostrar que los pasos del Algoritmo 1 propuesto en Kamvar et a. son correctos y computan $P_2x$.
\item Establecer una relacion con la proporción entre $\lambda_1 = 1$  y $|\lambda_2|$ para la convergencia de PageRank.
\end{itemize}